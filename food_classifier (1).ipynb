{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "food_classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "7p-mirXwdrwV"
      },
      "cell_type": "markdown",
      "source": [
        "# Multiclass Classification using Keras and TensorFlow on Food-101 Dataset  \n",
        "![alt text](https://www.vision.ee.ethz.ch/datasets_extra/food-101/static/img/food-101.jpg)\n",
        "\n",
        "**Food-101 Dataset** - https://www.vision.ee.ethz.ch/datasets_extra/food-101/\n",
        "\n",
        "_Notebook orignially contributed by: [Avinash Kappa](https://theimgclist.github.io/)_\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/community/en/multi_class_classification/food_classifier.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/community/en/multi_class_classification/food_classifier.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "7FChzwDISHbX"
      },
      "cell_type": "markdown",
      "source": [
        "# Install TensorFlow 2.0 Preview"
      ]
    },
    {
      "metadata": {
        "id": "CK9Zo5MXSOX0"
      },
      "cell_type": "markdown",
      "source": [
        "* TensorFlow 2.0 preview is available to test\n",
        "* Colab is the easiest way to try it\n",
        "* We can install TensorFlow 2.0 Preview using the below code cell"
      ]
    },
    {
      "metadata": {
        "id": "SFlLRjPyqQVI"
      },
      "cell_type": "code",
      "source": [
        "# Uncomment the below line of code if you want to try TensorFlow v2.0\n",
        "#!pip install tf-nightly-gpu-2.0-preview"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UpB4NvxbUZeg"
      },
      "cell_type": "markdown",
      "source": [
        "* Upgrading to TF 2.0 will be a critical process if you already have projects/code in other TF versions\n",
        "* tf_upgrade_v2 tool helps in converting existing TF code to TF 2.0\n",
        "* This tool is automatically installed by pip install for TensorFlow 1.13 and later\n",
        "* Below is an example of how to use this tool:\n",
        "\n",
        "`tf_upgrade_v2 --infile script.py --outfile script-upgraded.py`"
      ]
    },
    {
      "metadata": {
        "id": "Xa07tVPbP7Cu"
      },
      "cell_type": "markdown",
      "source": [
        "# Download and extract Food 101 Dataset"
      ]
    },
    {
      "metadata": {
        "id": "1xAnRxZycECw"
      },
      "cell_type": "markdown",
      "source": [
        "* Add all the imports"
      ]
    },
    {
      "metadata": {
        "id": "suJ5vUhtcK69"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import collections\n",
        "from collections import defaultdict\n",
        "\n",
        "from shutil import copy\n",
        "from shutil import copytree, rmtree\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JOZZbCDoP-Hy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4fc75bf-1ff1-47d2-984e-af2b1adb7591"
      },
      "cell_type": "code",
      "source": [
        "# Check TF version and whether GPU is enabled\n",
        "print(tf.__version__)\n",
        "print(tf.test.gpu_device_name())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n",
            "/device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Gv3pRiPjESPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a320ee-184f-4f2e-938e-ad0d238350cb"
      },
      "cell_type": "code",
      "source": [
        "# Clone tensorflow/examples repo which has images to evaluate trained model\n",
        "!git clone https://github.com/tensorflow/examples.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'examples'...\n",
            "remote: Enumerating objects: 23540, done.\u001b[K\n",
            "remote: Counting objects: 100% (500/500), done.\u001b[K\n",
            "remote: Compressing objects: 100% (334/334), done.\u001b[K\n",
            "remote: Total 23540 (delta 130), reused 422 (delta 92), pack-reused 23040\u001b[K\n",
            "Receiving objects: 100% (23540/23540), 44.04 MiB | 13.21 MiB/s, done.\n",
            "Resolving deltas: 100% (12779/12779), done.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "f88XvEBTQBS9"
      },
      "cell_type": "code",
      "source": [
        "# Helper function to download data and extract\n",
        "\n",
        "def get_data_extract():\n",
        "  if \"food-101\" in os.listdir():\n",
        "    print(\"Dataset already exists\")\n",
        "  else:\n",
        "    tf.keras.utils.get_file(\n",
        "    'food-101.tar.gz',\n",
        "    'http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz',\n",
        "    cache_subdir='/content',\n",
        "    extract=True,\n",
        "    archive_format='tar',\n",
        "    cache_dir=None\n",
        "    )\n",
        "    print(\"Dataset downloaded and extracted!\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gwLp2G9ae9xC"
      },
      "cell_type": "markdown",
      "source": [
        "* The Food-101 dataset is 5GB in size. This might take some time to finish.."
      ]
    },
    {
      "metadata": {
        "id": "O7kY0v23QJGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dbbac17-e2eb-4f0e-c705-b7b89dd2b721"
      },
      "cell_type": "code",
      "source": [
        "# Download data and extract it to folder\n",
        "get_data_extract()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
            "4996278331/4996278331 [==============================] - 206s 0us/step\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "eQr6hmptQe6q"
      },
      "cell_type": "markdown",
      "source": [
        "# Understand dataset structure and files"
      ]
    },
    {
      "metadata": {
        "id": "n0xi2zwVQsWq"
      },
      "cell_type": "markdown",
      "source": [
        "* The dataset being used is [Food 101](https://www.vision.ee.ethz.ch/datasets_extra/food-101/)\n",
        "* This dataset has 101000 images in total. It's a food dataset with 101 categories(multiclass)\n",
        "* Each type of food has 750 training samples and 250 test samples\n",
        "* Note found on the webpage of the dataset :  \n",
        "* On purpose, the training images were not cleaned, and thus still contain some amount of noise. This comes mostly in the form of intense colors and sometimes wrong labels. All images were rescaled to have a maximum side length of 512 pixels.\n",
        "* The entire dataset is 5GB in size"
      ]
    },
    {
      "metadata": {
        "id": "7wJ_OH1DQyrd"
      },
      "cell_type": "code",
      "source": [
        "# Check the extracted dataset folder\n",
        "os.listdir('food-101/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9M2OZ8O_RVhu"
      },
      "cell_type": "markdown",
      "source": [
        "**images** folder contains 101 folders with 1000 images  each  \n",
        "Each folder contains images of a specific food class"
      ]
    },
    {
      "metadata": {
        "id": "yy_pAK35Rbdi"
      },
      "cell_type": "code",
      "source": [
        "os.listdir('food-101/images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ld4DOKjzSdns"
      },
      "cell_type": "markdown",
      "source": [
        "**meta** folder contains the text files - train.txt and test.txt  \n",
        "**train.txt** contains the list of images that belong to training set  \n",
        "**test.txt** contains the list of images that belong to test set  \n",
        "**classes.txt** contains the list of all classes of food"
      ]
    },
    {
      "metadata": {
        "id": "jdIDm6tkSwqY"
      },
      "cell_type": "code",
      "source": [
        "os.listdir('food-101/meta')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "motIEZu_TVih"
      },
      "cell_type": "markdown",
      "source": [
        "# Visualize random image from each of the 101 classes"
      ]
    },
    {
      "metadata": {
        "id": "Jfif27Pr5KEn"
      },
      "cell_type": "code",
      "source": [
        "# Visualize the data, showing one image per class from 101 classes\n",
        "rows = 17\n",
        "cols = 6\n",
        "fig, ax = plt.subplots(rows, cols, figsize=(25,25))\n",
        "fig.suptitle(\"Showing one random image from each class\", y=1.05, fontsize=24) # Adding  y=1.05, fontsize=24 helped me fix the suptitle overlapping with axes issue\n",
        "data_dir = \"food-101/images/\"\n",
        "foods_sorted = sorted(os.listdir(data_dir))\n",
        "food_id = 0\n",
        "for i in range(rows):\n",
        "  for j in range(cols):\n",
        "    try:\n",
        "      food_selected = foods_sorted[food_id]\n",
        "      food_id += 1\n",
        "    except:\n",
        "      break\n",
        "    food_selected_images = os.listdir(os.path.join(data_dir,food_selected)) # returns the list of all files present in each food category\n",
        "    food_selected_random = np.random.choice(food_selected_images) # picks one food item from the list as choice, takes a list and returns one random item\n",
        "    img = plt.imread(os.path.join(data_dir,food_selected, food_selected_random))\n",
        "    ax[i][j].imshow(img)\n",
        "    ax[i][j].set_title(food_selected, pad = 10)\n",
        "\n",
        "plt.setp(ax, xticks=[],yticks=[])\n",
        "plt.tight_layout()\n",
        "# https://matplotlib.org/users/tight_layout_guide.html\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KIgareCETmct"
      },
      "cell_type": "markdown",
      "source": [
        "# Split the image data into train and test using train.txt and test.txt"
      ]
    },
    {
      "metadata": {
        "id": "xB0XMUX_5KMQ"
      },
      "cell_type": "code",
      "source": [
        "# Helper method to split dataset into train and test folders\n",
        "def prepare_data(filepath, src,dest):\n",
        "  classes_images = defaultdict(list)\n",
        "  with open(filepath, 'r') as txt:\n",
        "      paths = [read.strip() for read in txt.readlines()]\n",
        "      for p in paths:\n",
        "        food = p.split('/')\n",
        "        classes_images[food[0]].append(food[1] + '.jpg')\n",
        "\n",
        "  for food in classes_images.keys():\n",
        "    print(\"\\nCopying images into \",food)\n",
        "    if not os.path.exists(os.path.join(dest,food)):\n",
        "      os.makedirs(os.path.join(dest,food))\n",
        "    for i in classes_images[food]:\n",
        "      copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
        "  print(\"Copying Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LSgcYcqy5KUd"
      },
      "cell_type": "code",
      "source": [
        "# Prepare train dataset by copying images from food-101/images to food-101/train using the file train.txt\n",
        "print(\"Creating train data...\")\n",
        "prepare_data('food-101/meta/train.txt', 'food-101/images', 'food-101/train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JI65wZgT5Kb-"
      },
      "cell_type": "code",
      "source": [
        "# Prepare test data by copying images from food-101/images to food-101/test using the file test.txt\n",
        "print(\"Creating test data...\")\n",
        "prepare_data('food-101/meta/test.txt', 'food-101/images', 'food-101/test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xccc8PJP5K1G"
      },
      "cell_type": "code",
      "source": [
        "# Check how many files are in the train folder\n",
        "\n",
        "train_files = sum([len(files) for i, j, files in os.walk(\"food-101/train\")])\n",
        "print(\"Total number of samples in train folder\")\n",
        "print(train_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iz3fjQw25K3-"
      },
      "cell_type": "code",
      "source": [
        "# Check how many files are in the test folder\n",
        "test_files = sum([len(files) for i, j, files in os.walk(\"food-101/test\")])\n",
        "print(\"Total number of samples in test folder\")\n",
        "print(test_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O5rLWIHpUGWf"
      },
      "cell_type": "markdown",
      "source": [
        "# Create a subset of data with few classes (3)"
      ]
    },
    {
      "metadata": {
        "id": "q5N8FCksUWf6"
      },
      "cell_type": "markdown",
      "source": [
        "* We now have train and test data ready  \n",
        "* But to experiment and try different architectures, working on the whole data with 101 classes takes a lot of time and computation  \n",
        "* To proceed with further experiments, I am creating train_min and test_mini, limiting the dataset to 3 classes  \n",
        "* Since the original problem is multiclass classification which makes key aspects of architectural decisions different from that of binary classification, choosing 3 classes is a good start instead of 2"
      ]
    },
    {
      "metadata": {
        "id": "b9i8vGHYKO-g"
      },
      "cell_type": "code",
      "source": [
        "# List of all 101 types of foods(sorted alphabetically)\n",
        "foods_sorted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tYyJGTJ6J9CP"
      },
      "cell_type": "code",
      "source": [
        "# Helper method to create train_mini and test_mini data samples\n",
        "def dataset_mini(food_list, src, dest):\n",
        "  if os.path.exists(dest):\n",
        "    rmtree(dest) # removing dataset_mini(if it already exists) folders so that we will have only the classes that we want\n",
        "  os.makedirs(dest)\n",
        "  for food_item in food_list :\n",
        "    print(\"Copying images into\",food_item)\n",
        "    copytree(os.path.join(src,food_item), os.path.join(dest,food_item))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9YAscZLV5LFK"
      },
      "cell_type": "code",
      "source": [
        "# picking 3 food items and generating separate data folders for the same\n",
        "food_list = ['samosa','pizza','omelette']\n",
        "src_train = 'food-101/train'\n",
        "dest_train = 'food-101/train_mini'\n",
        "src_test = 'food-101/test'\n",
        "dest_test = 'food-101/test_mini'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tvlXbJ3NoPzy"
      },
      "cell_type": "code",
      "source": [
        "print(\"Creating train data folder with new classes\")\n",
        "dataset_mini(food_list, src_train, dest_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t7mWJCev5LI8"
      },
      "cell_type": "code",
      "source": [
        "print(\"Total number of samples in train folder\")\n",
        "train_files = sum([len(files) for i, j, files in os.walk(\"food-101/train_mini\")])\n",
        "print(train_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s4aeURey5LLy"
      },
      "cell_type": "code",
      "source": [
        "print(\"Creating test data folder with new classes\")\n",
        "dataset_mini(food_list, src_test, dest_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LBLq_gYD5LOm"
      },
      "cell_type": "code",
      "source": [
        "print(\"Total number of samples in test folder\")\n",
        "test_files = sum([len(files) for i, j, files in os.walk(\"food-101/test_mini\")])\n",
        "print(test_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jOsn6lpAV1fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E06AbW26V1iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G_rZdxAFV1kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QGh0nrBmV1nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KT2FJC3yV1qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M8mrofuDV1te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "upx61ukJiA8B"
      },
      "cell_type": "markdown",
      "source": [
        "# Fine tune Inception Pretrained model using Food 101 dataset"
      ]
    },
    {
      "metadata": {
        "id": "z5hh8fj8iIaV"
      },
      "cell_type": "markdown",
      "source": [
        "* Keras and other Deep Learning libraries provide pretrained models  \n",
        "* These are deep neural networks with efficient architectures(like VGG,Inception,ResNet) that are already trained on datasets like ImageNet  \n",
        "* Using these pretrained models, we can use the already learned weights and add few layers on top to finetune the model to our new data  \n",
        "* This helps in faster convergance and saves time and computation when compared to models trained from scratch"
      ]
    },
    {
      "metadata": {
        "id": "8AzJVmphi0VQ"
      },
      "cell_type": "markdown",
      "source": [
        "* We currently have a subset of dataset with 3 classes - samosa, pizza and omelette  \n",
        "* Use the below code to finetune Inceptionv3 pretrained model"
      ]
    },
    {
      "metadata": {
        "id": "MS5NI8Py77sA"
      },
      "cell_type": "code",
      "source": [
        "def train_model(n_classes,num_epochs, nb_train_samples,nb_validation_samples):\n",
        "  K.clear_session()\n",
        "\n",
        "  img_width, img_height = 299, 299\n",
        "  train_data_dir = 'food-101/train_mini'\n",
        "  validation_data_dir = 'food-101/test_mini'\n",
        "  batch_size = 16\n",
        "  bestmodel_path = 'bestmodel_'+str(n_classes)+'class.hdf5'\n",
        "  trainedmodel_path = 'trainedmodel_'+str(n_classes)+'class.hdf5'\n",
        "  history_path = 'history_'+str(n_classes)+'.log'\n",
        "\n",
        "  train_datagen = ImageDataGenerator(\n",
        "      preprocessing_function=preprocess_input,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True)\n",
        "\n",
        "  test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "      train_data_dir,\n",
        "      target_size=(img_height, img_width),\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical')\n",
        "\n",
        "  validation_generator = test_datagen.flow_from_directory(\n",
        "      validation_data_dir,\n",
        "      target_size=(img_height, img_width),\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical')\n",
        "\n",
        "\n",
        "  inception = InceptionV3(weights='imagenet', include_top=False)\n",
        "  x = inception.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dense(128,activation='relu')(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "\n",
        "  predictions = Dense(n_classes,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
        "\n",
        "  model = Model(inputs=inception.input, outputs=predictions)\n",
        "  model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  checkpoint = ModelCheckpoint(filepath=bestmodel_path, verbose=1, save_best_only=True)\n",
        "  csv_logger = CSVLogger(history_path)\n",
        "\n",
        "  history = model.fit_generator(train_generator,\n",
        "                      steps_per_epoch = nb_train_samples // batch_size,\n",
        "                      validation_data=validation_generator,\n",
        "                      validation_steps=nb_validation_samples // batch_size,\n",
        "                      epochs=num_epochs,\n",
        "                      verbose=1,\n",
        "                      callbacks=[csv_logger, checkpoint])\n",
        "\n",
        "  model.save(trainedmodel_path)\n",
        "  class_map = train_generator.class_indices\n",
        "  return history, class_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JBs1U7hZkp1U"
      },
      "cell_type": "code",
      "source": [
        "# Train the model with data from 3 classes\n",
        "n_classes = 3\n",
        "epochs = 5\n",
        "nb_train_samples = train_files\n",
        "nb_validation_samples = test_files\n",
        "\n",
        "history, class_map_3 = train_model(n_classes,epochs, nb_train_samples,nb_validation_samples)\n",
        "print(class_map_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KbDzLAHGpJXQ"
      },
      "cell_type": "markdown",
      "source": [
        "# Visualize the accuracy and loss plots"
      ]
    },
    {
      "metadata": {
        "id": "SjRm_AWZpPZm"
      },
      "cell_type": "code",
      "source": [
        "def plot_accuracy(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['acc']) # change acc to accuracy if testing TF 2.0\n",
        "    plt.plot(history.history['val_acc']) # change val_accuracy if testing TF 2.0\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_loss(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_accuracy(history,'FOOD101-Inceptionv3')\n",
        "plot_loss(history,'FOOD101-Inceptionv3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mQnoYY2ZPRrf"
      },
      "cell_type": "markdown",
      "source": [
        "* The plots show that the accuracy of the model increased with epochs and the loss has decreased\n",
        "* Validation accuracy has been on the higher side than training accuracy for many epochs\n",
        "* This could be for several reasons:\n",
        "  * We used a pretrained model trained on ImageNet which contains data from a variety of classes\n",
        "  * Using dropout can lead to a higher validation accuracy\n",
        "* The best model saved has a Top-1 validation accuracy of 93%\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "qjeWMHrCwSoS"
      },
      "cell_type": "markdown",
      "source": [
        "# Predicting classes for new images from internet using the best trained model"
      ]
    },
    {
      "metadata": {
        "id": "XBb-sj73pNc7"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Loading the best saved model to make predictions\n",
        "\n",
        "K.clear_session()\n",
        "model_best = load_model('bestmodel_3class.hdf5',compile = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nYTIzLhiRNKt"
      },
      "cell_type": "markdown",
      "source": [
        "* **Setting compile=False and clearing the session leads to faster loading of the saved model**\n",
        "* **Withouth the above addiitons, model loading was taking more than a minute!**"
      ]
    },
    {
      "metadata": {
        "id": "5MIBtyj1pFoK"
      },
      "cell_type": "code",
      "source": [
        "def predict_class(model, images, show = True):\n",
        "  for img in images:\n",
        "    img = image.load_img(img, target_size=(299, 299))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = preprocess_input(img)\n",
        "\n",
        "    pred = model.predict(img)\n",
        "    index = np.argmax(pred)\n",
        "    food_list.sort()\n",
        "    pred_value = food_list[index]\n",
        "    #print(pred)\n",
        "    if show:\n",
        "        plt.imshow(img[0])\n",
        "        plt.axis('off')\n",
        "        plt.title(pred_value)\n",
        "        plt.show()\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uzLVocClxD0f"
      },
      "cell_type": "code",
      "source": [
        "# Make a list of images and test the trained model\n",
        "images = []\n",
        "imagepath = '/content/examples/community/en/multi_class_classification/images/'\n",
        "images.append(imagepath+'samosa.jpg')\n",
        "images.append(imagepath+'pizza.jpg')\n",
        "images.append(imagepath+'omelette.jpg')\n",
        "predict_class(model_best, images, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uKdVXbH-O5uW"
      },
      "cell_type": "markdown",
      "source": [
        "The model got them all right!"
      ]
    },
    {
      "metadata": {
        "id": "rdaEgO6F7SBK"
      },
      "cell_type": "markdown",
      "source": [
        "# Fine tune Inceptionv3 model with 11 classes of data"
      ]
    },
    {
      "metadata": {
        "id": "OHItV3dTRpVS"
      },
      "cell_type": "markdown",
      "source": [
        "* We trained a model on 3 classes and tested it using new data\n",
        "* The model was able to predict the classes of all three test images correctly\n",
        "* Will it be able to perform at the same level of accuracy for more classes?\n",
        "* FOOD-101 dataset has 101 classes of data\n",
        "* Even with fine tuning using a pre-trained model, each epoch was taking more than an hour when all 101 classes of data is used(tried this on both Colab and on a Deep Learning VM instance with P100 GPU on GCP)\n",
        "* But to check how the model performs when more classes are included, I'm using the same model to fine tune and train on 11 randomly chosen classes\n"
      ]
    },
    {
      "metadata": {
        "id": "EUe06wqASS1s"
      },
      "cell_type": "code",
      "source": [
        "# Helper function to select n random food classes\n",
        "def pick_n_random_classes(n):\n",
        "  random.seed(9000)\n",
        "  food_list = []\n",
        "  random_food_indices = random.sample(range(len(foods_sorted)),n) # We are picking n random food classes\n",
        "  for i in random_food_indices:\n",
        "    food_list.append(foods_sorted[i])\n",
        "  food_list.sort()\n",
        "  print(\"These are the randomly picked food classes we will be training the model on...\\n\", food_list)\n",
        "  return food_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b1DiwFi3SSrV"
      },
      "cell_type": "code",
      "source": [
        "# Lets try with more classes than just 3. Also, this time lets randomly pick the food classes\n",
        "n = 11\n",
        "food_list = pick_n_random_classes(11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eyfKi0kqZQVo"
      },
      "cell_type": "code",
      "source": [
        "# Create the new data subset of n classes\n",
        "print(\"Creating training data folder with new classes...\")\n",
        "dataset_mini(food_list, src_train, dest_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LGtFFltY2T8N"
      },
      "cell_type": "code",
      "source": [
        "print(\"Total number of samples in train folder\")\n",
        "train_files = sum([len(files) for i, j, files in os.walk(\"food-101/train_mini\")])\n",
        "print(train_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kVyZYEVyZQm4"
      },
      "cell_type": "code",
      "source": [
        "print(\"Creating test data folder with new classes\")\n",
        "dataset_mini(food_list, src_test, dest_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_hP14tE0ZQvH"
      },
      "cell_type": "code",
      "source": [
        "print(\"Total number of samples in test folder\")\n",
        "test_files = sum([len(files) for i, j, files in os.walk(\"food-101/test_mini\")])\n",
        "print(test_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SyoYObOKZQ4j"
      },
      "cell_type": "code",
      "source": [
        "# Train the model with data from 3 classes\n",
        "n_classes = 11\n",
        "epochs = 5\n",
        "nb_train_samples = train_files\n",
        "nb_validation_samples = test_files\n",
        "\n",
        "history, class_map_11 = train_model(n_classes,epochs, nb_train_samples,nb_validation_samples)\n",
        "print(class_map_11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9j6jD5Ny9Mvh"
      },
      "cell_type": "code",
      "source": [
        "plot_accuracy(history,'FOOD101-Inceptionv3')\n",
        "plot_loss(history,'FOOD101-Inceptionv3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b8DakTjkZsxy"
      },
      "cell_type": "markdown",
      "source": [
        "* The plots show that the accuracy of the model increased with epochs and the loss has decreased\n",
        "* Validation accuracy has been on the higher side than training accuracy for many epochs\n",
        "* This could be for several reasons:\n",
        "  * We used a pretrained model trained on ImageNet which contains data from a variety of classes\n",
        "  * Using dropout can lead to a higher validation accuracy\n",
        "* I set number of epochs to just 10, as each epoch's taking around 6mins\n",
        "* loss is still decreasing, so the model can be trained for some more epochs\n",
        "* Increase the number of epochs for better accuracy\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "BAXYCwWF8TmY"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Loading the best saved model to make predictions\n",
        "\n",
        "K.clear_session()\n",
        "model_best = load_model('bestmodel_11class.hdf5',compile = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HAFb8xSj9Ygn"
      },
      "cell_type": "code",
      "source": [
        "# Make a list of downloaded images and test the trained model\n",
        "images = []\n",
        "images.append(imagepath+'friedrice.jpg')\n",
        "images.append(imagepath+'hotdog.jpg')\n",
        "images.append(imagepath+'icecream.jpg')\n",
        "images.append(imagepath+'pizza.jpg')\n",
        "predict_class(model_best, images, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AdOyy1CTZ-HJ"
      },
      "cell_type": "markdown",
      "source": [
        "* The model did well even when the number of classes are increased to 11\n",
        "* Model training on all 101 classes takes some time\n",
        "* It was taking more than an hour for one epoch when the full dataset is used for fine tuning"
      ]
    },
    {
      "metadata": {
        "id": "7feEa_xDaGE0"
      },
      "cell_type": "markdown",
      "source": [
        "# Summary of the things I tried\n",
        "* This notebook is the refactored and organised version of all the experiments and training trials I made\n",
        "* I used this very useful Keras blog - https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html for reference\n",
        "* I spent considerable amount of time in fixing things even before getting to the model training phase\n",
        "* For example, it took some time to get the image visualization plots aligned withouth any overlap\n",
        "* It is easier to go through a notebook and understand code someone else has taken hours to finish\n",
        "* I started with VGG16 pretrained model. It did give good validation accuracy after training for few epochs\n",
        "* I then tried Inceptionv3. VGG was taking more time for each epoch and since inception was also giving good validation accuracy, I chose Inception over VGG\n",
        "* For data augmentation, I sticked to the transformations used in the above blog\n",
        "* I didnt use TTA except rescaling test images\n",
        "* To avoid Colab connection issues during training, I set number of epochs to 10\n"
      ]
    },
    {
      "metadata": {
        "id": "xwX7VcZteclM"
      },
      "cell_type": "markdown",
      "source": [
        "# Further Improvements\n",
        "* Try more augmentation on test images\n",
        "* Fine tune the model on the entire dataset(for a few epochs atleast)\n",
        "* Play with hyper parameters, their values and see how it impacts model performance\n",
        "* There is currently no implementation to handle out of distribution / no class scenario. Can try below methods:\n",
        "    * Set a threshold for the class with highest score. When model gives prediction score below the threshold for its top prediction, the prediction can be classified as NO-CLASS / UNSEEN\n",
        "    * Add a new class called **NO-CLASS**, provide data from different classes other than those in the original dataset. This way the model also learns how to classify totally unseen/unrelated data\n",
        "    * I am yet to try these methods and not sure about the results\n",
        "* Recently published paper - [Rethinking ImageNet Pretraining](https://arxiv.org/abs/1811.08883 ), claims that training from random initialization instead of using pretrained weights is not only robust but also gives comparable results\n",
        "* Pre-trained models are surely helpful. They save a lot of time and computation. Yet, that shouldn't be the reason to not try to train a model from scratch\n"
      ]
    },
    {
      "metadata": {
        "id": "pkRM0qjBuFtw"
      },
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "* Deep Learning with Python by Francois Cholett - must read really!\n",
        "* [Building Powerful Image Classification Models](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
        "* [How Convolutional Neural Networks See the World](https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html)\n",
        "* [The Building Blocks of Interpretability](https://distill.pub/2018/building-blocks/)\n",
        "* [Feature Visualization](https://distill.pub/2017/feature-visualization/)"
      ]
    }
  ]
}